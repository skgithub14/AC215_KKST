{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDA.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"Oea1DUMA_bvY"},"source":["# Project EDA and Data Pre-processing"]},{"cell_type":"markdown","metadata":{"id":"ctkGlJ9lAZmy"},"source":["## Set-up"]},{"cell_type":"code","metadata":{"id":"9ayvnStyActh","executionInfo":{"status":"ok","timestamp":1635223067292,"user_tz":240,"elapsed":2864,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["import os\n","from os.path import join  \n","import requests\n","import zipfile\n","import tarfile\n","import shutil\n","import random\n","import math\n","import json\n","import time\n","import sys\n","import cv2\n","import string\n","import re\n","import subprocess\n","import hashlib\n","import numpy as np\n","import pandas as pd\n","from glob import glob\n","import collections\n","import unicodedata\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","import matplotlib.cm as cm\n","%matplotlib inline\n","\n","# Tensorflow\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.utils import to_categorical\n","from tensorflow.python.keras import backend as K\n","from tensorflow.python.keras.utils.layer_utils import count_params\n","\n","# sklearn\n","from sklearn.model_selection import train_test_split\n","\n","# Tensorflow Hub\n","import tensorflow_hub as hub\n","\n","# Colab auth\n","from google.colab import auth\n","from google.cloud import storage"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4kzvxwbRH7cf"},"source":["### GitHub Integration"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9Q9ZAOa_Syx","executionInfo":{"status":"ok","timestamp":1635223068341,"user_tz":240,"elapsed":1065,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"fb81dc9b-2663-4df3-f001-63e9b7a13600"},"source":["# Mount Google Drive\n","from google.colab import drive # import drive from google colab\n","\n","ROOT = \"/content/drive\"     # default location for the drive\n","print(ROOT)                 # print content of ROOT (Optional)\n","\n","drive.mount(ROOT, force_remount=True)           # we mount the google drive at /content/drive"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive\n","Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KYgvir8NBFDK","executionInfo":{"status":"ok","timestamp":1635223068342,"user_tz":240,"elapsed":11,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"8dfda5e4-b320-497f-bf84-797ce7331ad9"},"source":["# Integrate GitHub\n","\n","# each group member should add their own ENV_PATH here\n","# comment out other people's ENV_PATHs\n","# Steve:\n","# ENV_PATH = \"/content/drive/MyDrive/adv_practical_data_science/local-repo/AC215_KKST/.env\"\n","# Matt:\n","# Shih-ye:\n","# Al:\n","# Ed:\n","ENV_PATH = \"/content/drive/MyDrive/AC215_ED/AC215_KKST/.env\"\n","\n","# load environment variables\n","with open(ENV_PATH) as env:\n","  env_text = env.read()\n","env_list = env_text.split(\"\\n\")\n","PROJECT_PATH = env_list[0]\n","GIT_PATH = env_list[1]\n","EMAIL = env_list[2]\n","GIT_USERNAME = env_list[3]\n","\n","# expand paths\n","REPO_PATH = PROJECT_PATH + '/AC215_KKST'\n","NOTEBOOK_DIR_PATH = REPO_PATH + '/notebooks'\n","DATA_PATH = REPO_PATH + '/data'\n","\n","# change directory to the local repo's notebook folder\n","%cd '{NOTEBOOK_DIR_PATH}'"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/AC215_ED/AC215_KKST/notebooks\n"]}]},{"cell_type":"markdown","metadata":{"id":"5GD5ZrLuIEd7"},"source":["#### Cells for updating local/remote repos"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Md8eyXoIIW1Z","executionInfo":{"status":"ok","timestamp":1635223070559,"user_tz":240,"elapsed":2225,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"dc947d0a-1615-438e-ae1a-86f7ca21df69"},"source":["# This will update your local repo with work other group member's have done on the project so you can build on their work.\n","!git pull"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["remote: Enumerating objects: 9, done.\u001b[K\n","remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n","remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n","remote: Total 5 (delta 3), reused 5 (delta 3), pack-reused 0\u001b[K\n","Unpacking objects: 100% (5/5), done.\n","From https://github.com/skgithub14/AC215_KKST\n","   af9c755..99162ac  main       -> origin/main\n","Updating af9c755..99162ac\n","Fast-forward\n"," submissions/milestone2_KKST/Milestone2_EDA_with_baseline_models.ipynb | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"B4Wdt2IRHEH6","executionInfo":{"status":"ok","timestamp":1635223071108,"user_tz":240,"elapsed":553,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"245e9072-874e-4f7d-d2ef-351e67c6393f"},"source":["# check statuses of the files you changed\n","# this will give a list of files currently in the \"head\"\n","!git status"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes not staged for commit:\n","  (use \"git add <file>...\" to update what will be committed)\n","  (use \"git checkout -- <file>...\" to discard changes in working directory)\n","\n","\t\u001b[31mmodified:   EDA.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\n","\t\u001b[31m../data/flickr/\u001b[m\n","\n","no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hmdUCtQiIZrA","executionInfo":{"status":"ok","timestamp":1635223071864,"user_tz":240,"elapsed":760,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"48acfad8-160a-4c53-f808-ca45138b7003"},"source":["# add files you changed to the head\n","# this is where you tell Git which files you changed that you want to update your local repo with\n","\n","# add all files in your local repo to the head\n","!git add .\n","\n","# add all files you changed to the head\n","#!git add -u\n","\n","# add files by name that you want to add to the head\n","#!git add {filename1}\n","\n","# check statuses of the files you changed\n","# this will give a list of files currently in the \"head\"\n","!git status"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["On branch main\n","Your branch is up to date with 'origin/main'.\n","\n","Changes to be committed:\n","  (use \"git reset HEAD <file>...\" to unstage)\n","\n","\t\u001b[32mmodified:   EDA.ipynb\u001b[m\n","\n","Untracked files:\n","  (use \"git add <file>...\" to include in what will be committed)\n","\n","\t\u001b[31m../data/flickr/\u001b[m\n","\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pAcgf0E6IfP2","executionInfo":{"status":"ok","timestamp":1635223072472,"user_tz":240,"elapsed":612,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"305fc0b9-dc53-4de7-8cbd-c73c39dbda92"},"source":["# commit the changes in the head to your local repo\n","# note if your message is too long the the commit will not work, keep it under 50 characters.\n","!git commit -m \"updated caption EDA\"\n","!git config --global user.email \"ed.bayes@mde.harvard.edu\"\n","!git config --global user.name \"ebayes\""],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["[main dd40cde] updated caption EDA\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite notebooks/EDA.ipynb (96%)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5IhWojgFJzSt","executionInfo":{"status":"ok","timestamp":1635223074036,"user_tz":240,"elapsed":1568,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"2717dc03-eb58-4305-9dd8-71fe8cf196a7"},"source":["# push the changes in your local repo to the group's remote repo develop branch\n","#!git push origin develop\n","\n","# push the changes in your local repo to the group's remote repo master branch\n","# note that only changes which have been thorough tested and validated should be committed to the master branch\n","!git push origin\n","\n","# you can also create additional branches for the remote repo as desired"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Counting objects: 4, done.\n","Delta compression using up to 2 threads.\n","Compressing objects:  25% (1/4)   \rCompressing objects:  50% (2/4)   \rCompressing objects:  75% (3/4)   \rCompressing objects: 100% (4/4)   \rCompressing objects: 100% (4/4), done.\n","Writing objects:  25% (1/4)   \rWriting objects:  50% (2/4)   \rWriting objects:  75% (3/4)   \rWriting objects: 100% (4/4)   \rWriting objects: 100% (4/4), 1.43 KiB | 292.00 KiB/s, done.\n","Total 4 (delta 3), reused 0 (delta 0)\n","remote: Resolving deltas: 100% (3/3), completed with 3 local objects.\u001b[K\n","To https://github.com/skgithub14/AC215_KKST.git\n","   99162ac..dd40cde  main -> main\n"]}]},{"cell_type":"markdown","metadata":{"id":"Kbeh3FY8ReWi"},"source":["### Verify Set-up"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yje1bCrBRvBF","executionInfo":{"status":"ok","timestamp":1635223074841,"user_tz":240,"elapsed":809,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"e580e0cf-9aa0-48f5-8cd4-4ea90bd5606f"},"source":["# Enable/Disable Eager Execution\n","# Reference: https://www.tensorflow.org/guide/eager\n","# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n","# without building graphs\n","\n","#tf.compat.v1.disable_eager_execution()\n","#tf.compat.v1.enable_eager_execution()\n","\n","print(\"tensorflow version\", tf.__version__)\n","print(\"keras version\", tf.keras.__version__)\n","print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n","\n","# Get the number of replicas \n","strategy = tf.distribute.MirroredStrategy()\n","print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n","\n","devices = tf.config.experimental.get_visible_devices()\n","print(\"Devices:\", devices)\n","print(tf.config.experimental.list_logical_devices('GPU'))\n","\n","print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n","print(\"All Physical Devices\", tf.config.list_physical_devices())\n","\n","# Better performance with the tf.data API\n","# Reference: https://www.tensorflow.org/guide/data_performance\n","AUTOTUNE = tf.data.experimental.AUTOTUNE"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["tensorflow version 2.6.0\n","keras version 2.6.0\n","Eager Execution Enabled: True\n","INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n","Number of replicas: 1\n","Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n","GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gzevKCiJR0hz","executionInfo":{"status":"ok","timestamp":1635223074841,"user_tz":240,"elapsed":11,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"2271cc0f-4865-478f-d972-4b454861a0ba"},"source":["!nvidia-smi"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Oct 26 04:37:54 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    74W / 149W |    123MiB / 11441MiB |      3%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"yy7FOHrBSPI0"},"source":["### Utilities"]},{"cell_type":"code","metadata":{"id":"zFEWcQ0dSM7g","executionInfo":{"status":"ok","timestamp":1635223075164,"user_tz":240,"elapsed":327,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["def download_file(packet_url, base_path=\"\", extract=False, headers=None):\n","  if base_path != \"\":\n","    if not os.path.exists(base_path):\n","      os.mkdir(base_path)\n","  packet_file = os.path.basename(packet_url)\n","  with requests.get(packet_url, stream=True, headers=headers) as r:\n","      r.raise_for_status()\n","      with open(os.path.join(base_path,packet_file), 'wb') as f:\n","          for chunk in r.iter_content(chunk_size=8192):\n","              f.write(chunk)\n","  \n","  if extract:\n","    if packet_file.endswith(\".zip\"):\n","      with zipfile.ZipFile(os.path.join(base_path,packet_file)) as zfile:\n","        zfile.extractall(base_path)\n","    else:\n","      packet_name = packet_file.split('.')[0]\n","      with tarfile.open(os.path.join(base_path,packet_file)) as tfile:\n","        tfile.extractall(base_path)\n","\n","def compute_dataset_metrics(data_list):\n","  data_list_with_metrics = []\n","  for item in data_list:\n","    img_path = FIMAGES + '/' + item[0]\n","    image = cv2.imread(img_path)\n","    data_list_with_metrics.append((img_path,image.shape[0],image.shape[1],image.nbytes / (1024 * 1024.0)))\n","\n","  # Build a dataframe\n","  data_list_with_metrics = np.asarray(data_list_with_metrics)\n","  dataset_df = pd.DataFrame({\n","    'path': data_list_with_metrics[:, 0],\n","    'height': data_list_with_metrics[:, 1],\n","    'width': data_list_with_metrics[:, 2],\n","    'size': data_list_with_metrics[:, 3],\n","    })\n","  \n","  dataset_df[\"height\"] = dataset_df[\"height\"].astype(int)\n","  dataset_df[\"width\"] = dataset_df[\"width\"].astype(int)\n","  dataset_df[\"size\"] = dataset_df[\"size\"].astype(float)\n","\n","  dataset_mem_size = dataset_df[\"size\"].sum()\n","  height_details = dataset_df[\"height\"].describe()\n","  width_details = dataset_df[\"width\"].describe()\n","\n","  print(\"Dataset Metrics:\")\n","  print(\"----------------\")\n","  print(\"Image Width:\")\n","  print(\"Min:\",width_details[\"min\"],\" Max:\",width_details[\"max\"])\n","  print(\"Image Height:\")\n","  print(\"Min:\",height_details[\"min\"],\" Max:\",height_details[\"max\"])\n","  print(\"Size in memory:\",round(dataset_df[\"size\"].sum(),2),\"MB\")\n","\n","class JsonEncoder(json.JSONEncoder):\n","  def default(self, obj):\n","    if isinstance(obj, np.integer):\n","        return int(obj)\n","    elif isinstance(obj, np.floating):\n","        return float(obj)\n","    elif isinstance(obj, decimal.Decimal):\n","        return float(obj)\n","    elif isinstance(obj, np.ndarray):\n","        return obj.tolist()\n","    else:\n","        return super(JsonEncoder, self).default(obj)\n","\n","experiment_name = None\n","def create_experiment():\n","  global experiment_name\n","  experiment_name = \"experiment_\" + str(int(time.time()))\n","\n","  # Create experiment folder\n","  if not os.path.exists(experiment_name):\n","      os.mkdir(experiment_name)\n","\n","def upload_experiment(data_details):\n","  # Check Bucket Access\n","  bucket_name = \"ac215-mushroom-app-models\" # BUCKET NAME\n","\n","  # List buckets in a GCP project\n","  storage_client = storage.Client(project=\"ac215-project\") # PROJECT ID \n","\n","  # Get bucket for Experiments\n","  bucket = storage_client.get_bucket(bucket_name)\n","  print(\"Model Bucket:\",bucket)\n","\n","  save_data_details(data_details)\n","\n","  # Copy the experiment folder to GCP Bucket\n","  for file_path in glob(experiment_name+'/*'):\n","    print(file_path)\n","    blob = bucket.blob(os.path.join(user_account,file_path)) \n","    print('uploading file', file_path)\n","    blob.upload_from_filename(file_path)\n","\n","def save_data_details(data_details):\n","  with open(os.path.join(experiment_name,\"data_details.json\"), \"w\") as json_file:\n","    json_file.write(json.dumps(data_details,cls=JsonEncoder))\n","\n","def save_model(model,model_name=\"model01\"):\n","\n","  # Save the enitire model (structure + weights)\n","  model.save(os.path.join(experiment_name,model_name+\".hdf5\"))\n","\n","  # Save only the weights\n","  model.save_weights(os.path.join(experiment_name,model_name+\".h5\"))\n","\n","  # Save the structure only\n","  model_json = model.to_json()\n","  with open(os.path.join(experiment_name,model_name+\".json\"), \"w\") as json_file:\n","      json_file.write(model_json)\n","\n","def get_model_size(model_name=\"model01\"):\n","  model_size = os.stat(os.path.join(experiment_name,model_name+\".h5\")).st_size\n","  return model_size\n","\n","def append_training_history(model_train_history, prev_model_train_history):\n","  for metric in [\"loss\",\"val_loss\",\"accuracy\",\"val_accuracy\"]:\n","    for metric_value in prev_model_train_history[metric]:\n","      model_train_history[metric].append(metric_value)\n","  \n","  return model_train_history\n","\n","def evaluate_save_model(model,test_data, model_train_history,execution_time, learning_rate, batch_size, epochs, optimizer,save=True):\n","  \n","  # Get the number of epochs the training was run for\n","  num_epochs = len(model_train_history[\"loss\"])\n","\n","  # Plot training results\n","  fig = plt.figure(figsize=(15,5))\n","  axs = fig.add_subplot(1,2,1)\n","  axs.set_title('Loss')\n","  # Plot all metrics\n","  for metric in [\"loss\",\"val_loss\"]:\n","      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n","  axs.legend()\n","  \n","  axs = fig.add_subplot(1,2,2)\n","  axs.set_title('Accuracy')\n","  # Plot all metrics\n","  for metric in [\"accuracy\",\"val_accuracy\"]:\n","      axs.plot(np.arange(0, num_epochs), model_train_history[metric], label=metric)\n","  axs.legend()\n","\n","  plt.show()\n","  \n","  # Evaluate on test data\n","  evaluation_results = model.evaluate(test_data)\n","  print(evaluation_results)\n","  \n","  if save:\n","    # Save model\n","    save_model(model, model_name=model.name)\n","    model_size = get_model_size(model_name=model.name)\n","\n","    # Save model history\n","    with open(os.path.join(experiment_name,model.name+\"_train_history.json\"), \"w\") as json_file:\n","        json_file.write(json.dumps(model_train_history,cls=JsonEncoder))\n","\n","    trainable_parameters = count_params(model.trainable_weights)\n","    non_trainable_parameters = count_params(model.non_trainable_weights)\n","\n","    # Save model metrics\n","    metrics ={\n","        \"trainable_parameters\":trainable_parameters,\n","        \"execution_time\":execution_time,\n","        \"loss\":evaluation_results[0],\n","        \"accuracy\":evaluation_results[1],\n","        \"model_size\":model_size,\n","        \"learning_rate\":learning_rate,\n","        \"batch_size\":batch_size,\n","        \"epochs\":epochs,\n","        \"optimizer\":type(optimizer).__name__\n","    }\n","    with open(os.path.join(experiment_name,model.name+\"_model_metrics.json\"), \"w\") as json_file:\n","        json_file.write(json.dumps(metrics,cls=JsonEncoder))"],"execution_count":11,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CHK1UBxBRhIK"},"source":["## Data Sets"]},{"cell_type":"markdown","metadata":{"id":"JkEBNKNLRyiE"},"source":["### Download and Read In"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3DXyq8E5SaVh","executionInfo":{"status":"ok","timestamp":1635223214545,"user_tz":240,"elapsed":139385,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"c2ad60b1-7041-4fb3-e48f-0d8de36e71f0"},"source":["# FLICKR data\n","# download\n","start_time = time.time()\n","download_file(\"https://storage.googleapis.com/ac215-project/flickr_data.zip\", base_path=DATA_PATH + '/flickr', extract=True)\n","execution_time = (time.time() - start_time)/60.0\n","print(\"Download execution time (mins)\",execution_time)\n","\n","# read-in\n","FLICKR_PATH = DATA_PATH + '/flickr'\n","fcaps = pd.read_csv(os.path.join(FLICKR_PATH,\"captions.txt\"))"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["Download execution time (mins) 2.3202585419019064\n"]}]},{"cell_type":"markdown","metadata":{"id":"7T6-fT4RR0QU"},"source":["### Explore Data Shape"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":291},"id":"lp0bBFcg9mo_","executionInfo":{"status":"ok","timestamp":1635223214548,"user_tz":240,"elapsed":20,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"3267fbcf-09cb-43bc-8d62-52e4e269e5e3"},"source":["# explore the captions\n","print(\"Number of rows:\",fcaps.shape[0])\n","print(\"Unique image names:\",len(pd.unique(fcaps['image'])))\n","print(\"Unique captions:\",len(pd.unique(fcaps['caption'])))\n","print(\"Unique rows:\",len(fcaps.value_counts()))\n","print(\"Head:\")\n","fcaps.head()"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of rows: 40455\n","Unique image names: 8091\n","Unique captions: 40201\n","Unique rows: 40445\n","Head:\n"]},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>image</th>\n","      <th>caption</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1000268201_693b08cb0e.jpg</td>\n","      <td>A child in a pink dress is climbing up a set o...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1000268201_693b08cb0e.jpg</td>\n","      <td>A girl going into a wooden building .</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1000268201_693b08cb0e.jpg</td>\n","      <td>A little girl climbing into a wooden playhouse .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1000268201_693b08cb0e.jpg</td>\n","      <td>A little girl climbing the stairs to her playh...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1000268201_693b08cb0e.jpg</td>\n","      <td>A little girl in a pink dress going into a woo...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                       image                                            caption\n","0  1000268201_693b08cb0e.jpg  A child in a pink dress is climbing up a set o...\n","1  1000268201_693b08cb0e.jpg              A girl going into a wooden building .\n","2  1000268201_693b08cb0e.jpg   A little girl climbing into a wooden playhouse .\n","3  1000268201_693b08cb0e.jpg  A little girl climbing the stairs to her playh...\n","4  1000268201_693b08cb0e.jpg  A little girl in a pink dress going into a woo..."]},"metadata":{},"execution_count":13}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gvVrmQsaDiDa","executionInfo":{"status":"ok","timestamp":1635223215115,"user_tz":240,"elapsed":582,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}},"outputId":"88bfe6ee-f081-4e0f-b4cf-b90cf5aa9050"},"source":["# explore the images\n","FIMAGES = FLICKR_PATH + '/Images'\n","print(\"Counting all .png files in: \" + FIMAGES)\n","x=0\n","for files in os.listdir(FIMAGES):\n","    if files.endswith('.jpg'):\n","        x+=1\n","print(x)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["Counting all .png files in: /content/drive/MyDrive/AC215_ED/AC215_KKST/data/flickr/Images\n","8091\n"]}]},{"cell_type":"markdown","metadata":{"id":"kSkSIpSFvuyP"},"source":["### Explore Captions"]},{"cell_type":"code","metadata":{"id":"OdRfEpSo1vmP"},"source":["#lemmatize captions with stopwords removal\n","import spacy\n","nlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n","fcaps['lemmatized'] = fcaps['caption'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))\n","\n","# calcaulate length of captions\n","fcaps['word_count'] = fcaps['caption'].apply(lambda x: len(str(x).split()))\n","fcaps['letter_count'] = fcaps['caption'].astype(str).apply(len)\n","\n","# sentiment analysis\n","from textblob import TextBlob\n","fcaps['polarity'] = fcaps['caption'].map(lambda text: TextBlob(text).sentiment.polarity)\n","\n","# fcaps.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OCEMqDdm7hN1"},"source":["plt.figure(figsize=(50,30))\n","plt.margins(0.02)\n","plt.xlabel('Sentiment', fontsize=50)\n","plt.xticks(fontsize=40)\n","plt.ylabel('Frequency', fontsize=50)\n","plt.yticks(fontsize=40)\n","plt.hist(fcaps['polarity'], bins=50)\n","plt.title('Sentiment Distribution', fontsize=60)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4Q644Cz2cvz","executionInfo":{"status":"ok","timestamp":1635223538017,"user_tz":240,"elapsed":318,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# term frequency analysis\n","words = fcaps['lemmatized']\n","allwords = []\n","for wordlist in words:\n","    allwords += wordlist\n","# print(allwords)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"JESbtq-95TkE"},"source":["import nltk\n","from nltk.probability import FreqDist\n","mostcommon_small = FreqDist(allwords).most_common(10)\n","x, y = zip(*mostcommon_small)\n","plt.figure(figsize=(50,30))\n","plt.margins(0.02)\n","plt.bar(x, y)\n","plt.xlabel('Words', fontsize=50)\n","plt.ylabel('Frequency of Words', fontsize=50)\n","plt.yticks(fontsize=40)\n","plt.xticks(rotation=60, fontsize=40)\n","plt.title('Frequency of 10 Most Common Words', fontsize=60)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w9gHMw7j2auP"},"source":["# Average Number of Letters per Caption Distribution\n","letter_avg = fcaps.groupby('caption')['letter_count'].mean().plot(kind='bar', figsize=(50,30))\n","plt.xlabel('caption', fontsize=35)\n","plt.ylabel('Count of Letters in Caption', fontsize=35)\n","plt.xticks(fontsize=40)\n","plt.yticks(fontsize=40)\n","plt.title('Average Number of Letters per Caption Distribution', fontsize=40)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"n0pvDTf-3Alm","executionInfo":{"status":"aborted","timestamp":1635223226425,"user_tz":240,"elapsed":16,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Average Number of Words per Caption Distribution\n","word_avg = fcaps.groupby('caption')['word_count'].mean().plot(kind='bar', figsize=(50,30))\n","plt.xlabel('caption', fontsize=35)\n","plt.ylabel('Count of Words in Caption', fontsize=35)\n","plt.xticks(fontsize=40)\n","plt.yticks(fontsize=40)\n","plt.title('Average Number of Words per Rating Distribution', fontsize=40)\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uTtiOcFuRtAQ"},"source":["### Sample Images"]},{"cell_type":"code","metadata":{"id":"1AqGUQU4IZJ8","executionInfo":{"status":"aborted","timestamp":1635223226426,"user_tz":240,"elapsed":17,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# retrieve an image and caption\n","this_img = fcaps.iloc[1][0]\n","print(this_img)\n","print(fcaps.iloc[1][1])\n","image = cv2.imread(FIMAGES + '/' + this_img)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","plt.imshow(image)\n","plt.axis('off')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5EEKr_-xKvfa","executionInfo":{"status":"aborted","timestamp":1635223226427,"user_tz":240,"elapsed":18,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# retrieve a sample of images and captions\n","# Generate a random sample of index\n","image_samples = np.random.randint(0,high=len(pd.unique(fcaps['image']))-1, size=10)\n","\n","fig = plt.figure(figsize=(20,20))\n","for i,img_idx in enumerate(image_samples):\n","    axs = fig.add_subplot(5,2,i+1)\n","    axs.set_title(fcaps.iloc[img_idx][1])\n","    # Read image\n","    image = cv2.imread(FIMAGES + '/' + fcaps.iloc[img_idx][0])\n","    # convert to rgb\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    plt.imshow(image)\n","    plt.axis('off')\n","\n","plt.suptitle(\"Sample Images\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JxIBVYrjRj2R"},"source":["### Data Set Metrics"]},{"cell_type":"code","metadata":{"id":"VEGBiAeHNSWA","executionInfo":{"status":"aborted","timestamp":1635223226427,"user_tz":240,"elapsed":18,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Compute dataset metrics\n","# only do this for unique images (each image has multiple possible captions)\n","u_images = pd.unique(fcaps['image'])\n","u_images_df = pd.DataFrame({\n","    'image': u_images,\n","    'ind': range(0,len(u_images))\n","    })\n","u_images_df[\"ind\"] = u_images_df[\"ind\"].astype(str)\n","u_images_list = u_images_df.values.tolist()\n","compute_dataset_metrics(u_images_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GnpjrzorSEyn"},"source":["## Build Data Pipelines"]},{"cell_type":"markdown","metadata":{"id":"RDAV-8ikJVSe"},"source":["### Pre-process"]},{"cell_type":"code","metadata":{"id":"DIaRJmlIJh0Y","executionInfo":{"status":"aborted","timestamp":1635223226428,"user_tz":240,"elapsed":18,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Choose the top 10000 words from the vocabulary\n","top_k = 10000\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=top_k,\n","                                                  oov_token=\"<unk>\",\n","                                                  filters='!\"#$%&()*+.,-/:;=?@[\\]^_`{|}~')\n","\n","all_captions = [itm[1] for itm in fcaps_list]\n","\n","tokenizer.fit_on_texts(all_captions)\n","\n","tokenizer.word_index['<pad>'] = 0\n","tokenizer.index_word[0] = '<pad>'\n","\n","# Create the tokenized vectors\n","train_seqs = tokenizer.texts_to_sequences(data_y)\n","\n","print(\"Example tokenized caption:\", train_seqs[0])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jHNsLhgGJt5c","executionInfo":{"status":"aborted","timestamp":1635223226428,"user_tz":240,"elapsed":18,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Pad each vector to the max_length of the captions\n","# If you do not provide a max_length value, pad_sequences calculates it automatically\n","cap_vector = tf.keras.preprocessing.sequence.pad_sequences(train_seqs, padding='post')\n","\n","# Find the maximum length of any caption in the dataset\n","def calc_max_length(tensor):\n","    return max(len(t) for t in tensor)\n","max_length = calc_max_length(train_seqs)\n","print(\"Max caption length:\", max_length)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vqiZbjCPJZS7"},"source":["### Split the Data"]},{"cell_type":"code","metadata":{"id":"tjDaM6kQLC6V","executionInfo":{"status":"aborted","timestamp":1635223226429,"user_tz":240,"elapsed":19,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Download image files\n","IMAGE_PATH = FLICKR_PATH + '/Images'\n","\n","# Group all captions together having the same image ID.\n","image_path_to_caption = collections.defaultdict(list)\n","for val in fcaps_list:\n","  caption = f\"<start> {val[1]} <end>\"\n","  image_path = IMAGE_PATH + '/' + val[0]\n","  image_path_to_caption[image_path].append(caption)\n","\n","# randomly shuffle the image order\n","image_paths = list(image_path_to_caption.keys())\n","random.shuffle(image_paths)\n","image_paths_order = image_paths.copy()\n","\n","# create x and y data\n","data_y = []\n","data_x = []\n","for image_path in image_paths_order:\n","  caption_list = image_path_to_caption[image_path]\n","  data_y.extend(caption_list)\n","  data_x.extend([image_path] * len(caption_list))\n","\n","print(\"data_x:\",len(data_x))\n","print(\"data_y:\",len(data_y))\n","print(\"data_x:\",data_x[:5])\n","print(\"data_y:\",data_y[:5])\n","\n","# Re-group all captions together having the same image ID, for x and y data\n","img_to_cap_vector = collections.defaultdict(list)\n","for img, cap in zip(data_x, data_y):\n","  img_to_cap_vector[img].append(cap)\n","\n","# example dictionary element (keyed by image name)\n","print(\"Dictionary: \",len(img_to_cap_vector))\n","print(\"Example dictionary element: \",img_to_cap_vector[IMAGE_PATH + '/3329254388_27017bab30.jpg'])\n","\n","# train/test split\n","test_percent = 0.10\n","img_keys = list(img_to_cap_vector.keys())\n","slice_index = int(len(img_keys)*(1-test_percent))\n","img_name_train_val_keys, img_name_test_keys = img_keys[:slice_index], img_keys[slice_index:]\n","\n","train_val_x = []\n","train_val_y = []\n","for imgt in img_name_train_val_keys:\n","  capt_len = len(img_to_cap_vector[imgt])\n","  train_val_x.extend([imgt] * capt_len)\n","  train_val_y.extend(img_to_cap_vector[imgt])\n","\n","test_x = []\n","test_y = []\n","for imgt in img_name_test_keys:\n","  capt_len = len(img_to_cap_vector[imgt])\n","  test_x.extend([imgt] * capt_len)\n","  test_y.extend(img_to_cap_vector[imgt])\n","\n","# train/val split\n","val_percent = 0.20\n","img_keys = list(img_to_cap_vector.keys())\n","slice_index = int(len(img_keys)*(1-val_percent))\n","img_name_train_keys, img_name_val_keys = img_keys[:slice_index], img_keys[slice_index:]\n","\n","train_x = []\n","train_y = []\n","for imgt in img_name_train_keys:\n","  capt_len = len(img_to_cap_vector[imgt])\n","  train_x.extend([imgt] * capt_len)\n","  train_y.extend(img_to_cap_vector[imgt])\n","\n","val_x = []\n","val_y = []\n","for imgt in img_name_val_keys:\n","  capt_len = len(img_to_cap_vector[imgt])\n","  val_x.extend([imgt] * capt_len)\n","  val_y.extend(img_to_cap_vector[imgt])\n","\n","print(\"train_x count:\",len(train_x))\n","print(\"train_y count:\",len(train_y))\n","\n","print(\"validate_x count:\",len(validate_x))\n","print(\"validate_y count:\",len(validate_y))\n","\n","print(\"test_x count:\",len(test_x))\n","print(\"test_y count:\",len(test_y))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tJ4R19iZTHqK"},"source":["### Create TF Datasets"]},{"cell_type":"code","metadata":{"id":"hg1yY8HprFT1","executionInfo":{"status":"aborted","timestamp":1635223226429,"user_tz":240,"elapsed":19,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# Feel free to change these parameters according to your system's configuration\n","# top_k = 10000\n","# max_length = 37\n","batch_size = 128\n","# BUFFER_SIZE = 1000\n","train_shuffle_buffer_size= len(train_x)\n","validation_shuffle_buffer_size= len(val_x)\n","embedding_dim = 256\n","units = 512\n","vocab_size = top_k + 1\n","num_steps = len(train_x) // batch_size\n","image_width = 224 # 255 or 299?\n","image_height = 224 # 255 or 299?\n","num_channels = 3\n","# Shape of the vector extracted from InceptionV3 is (64, 2048)\n","# These two variables represent that vector shape\n","features_shape = 2048\n","attention_features_shape = 64"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zuVB4V7ure5A","executionInfo":{"status":"aborted","timestamp":1635223226430,"user_tz":240,"elapsed":19,"user":{"displayName":"Edward Bayes","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBS8uPqNfCqU1vJVNp318bH_svd_rbG4HtV7-5mQ=s64","userId":"09014545777139056358"}}},"source":["# dataset = tf.data.Dataset.from_tensor_slices((img_name_train, cap_train))\n","# Create TF Dataset\n","train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n","validation_data = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n","test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n","\n","# Load Image\n","def load_image(path, label):\n","  image = tf.io.read_file(path)\n","  image = tf.image.decode_jpeg(image, channels=num_channels)\n","  image = tf.image.resize(image, [image_height,image_width])\n","  return image, label\n","\n","# Normalize pixels\n","def normalize(image, label):\n","  image = image/255\n","  image = tf.keras.applications.inception_v3.preprocess_input(image)\n","  #image = keras.applications.mobilenet.preprocess_input(image)\n","  return image, label\n","\n","#############\n","# Train data\n","#############\n","# Apply all data processing logic\n","train_data = train_data.shuffle(buffer_size=train_shuffle_buffer_size)\n","train_data = train_data.map(load_image, num_parallel_calls=AUTOTUNE)\n","train_data = train_data.map(normalize, num_parallel_calls=AUTOTUNE)\n","train_data = train_data.batch(batch_size)\n","train_data = train_data.prefetch(AUTOTUNE)\n","\n","##################\n","# Validation data\n","##################\n","# Apply all data processing logic\n","validation_data = validation_data.shuffle(buffer_size=validation_shuffle_buffer_size)\n","validation_data = validation_data.map(load_image, num_parallel_calls=AUTOTUNE)\n","validation_data = validation_data.map(normalize, num_parallel_calls=AUTOTUNE)\n","validation_data = validation_data.batch(batch_size)\n","validation_data = validation_data.prefetch(AUTOTUNE)\n","\n","############\n","# Test data\n","############\n","# Apply all data processing logic\n","test_data = test_data.map(load_image, num_parallel_calls=AUTOTUNE)\n","test_data = test_data.map(normalize, num_parallel_calls=AUTOTUNE)\n","test_data = test_data.batch(batch_size)\n","test_data = test_data.prefetch(AUTOTUNE)\n","\n","print(\"train_data\",train_data)\n","print(\"validation_data\",validation_data)\n","print(\"test_data\",test_data)"],"execution_count":null,"outputs":[]}]}